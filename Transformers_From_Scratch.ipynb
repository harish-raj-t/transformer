{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fae581-6f94-40bd-a158-1439044f81a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29653730>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence,pack_padded_sequence, pad_packed_sequence\n",
    "import os\n",
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34ba9a1a-02e3-49c5-82c6-2264da8ffa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emd_dim, heads=4, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        assert emd_dim % heads == 0\n",
    "        self.heads = heads\n",
    "        self.head_dim = emd_dim//heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.multiHead = nn.Linear(emd_dim, emd_dim*3)\n",
    "        self.output = nn.Linear(emd_dim,emd_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_masking(attn_scores, padding_mask):\n",
    "        col_mask = padding_mask[:, None, None, :]\n",
    "        attn_scores.masked_fill_((col_mask == 0), float('-inf'))\n",
    "        return attn_scores\n",
    "\n",
    "    def forward(self, x, padding_mask=None, attn_mask=False):\n",
    "        B, T, C = x.shape\n",
    "        qkv = self.multiHead(x)\n",
    "        q, k, v = torch.chunk(qkv,3,dim=-1)\n",
    "        q = q.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        k = k.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        v = v.view(B, T, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        attn_scores = torch.matmul(q, k.transpose(-2, -1)) * self.scale\n",
    "        if attn_mask:\n",
    "            tril = torch.tril(torch.ones(T,T))\n",
    "            attn_scores = attn_scores.masked_fill(tril==0, float('-inf'))\n",
    "        if padding_mask is not None:\n",
    "            attn_scores = self.add_masking(attn_scores, padding_mask)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_probs_drop = self.dropout(attn_probs)\n",
    "        attn_output = torch.matmul(attn_probs_drop,v)\n",
    "        fn_attn_output = attn_output.permute(0, 2, 1, 3).reshape(B, T, C)\n",
    "        return self.output(fn_attn_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cf83835-714c-4e0f-8d69-439f7eb92909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, emd_dim, heads=4, dropout = 0.2):\n",
    "        super().__init__()\n",
    "        assert emd_dim % heads == 0\n",
    "        self.heads = heads\n",
    "        self.head_dim = emd_dim//heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        self.Wk = nn.Linear(emd_dim, emd_dim)\n",
    "        self.Wq = nn.Linear(emd_dim, emd_dim)\n",
    "        self.Wv = nn.Linear(emd_dim, emd_dim)\n",
    "        self.output = nn.Linear(emd_dim,emd_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def add_masking(attn_scores, padding_mask):\n",
    "        if padding_mask is not None:\n",
    "            col_mask = padding_mask[:, None, None, :]\n",
    "            attn_scores.masked_fill_((col_mask == 0), float('-inf'))\n",
    "        return attn_scores\n",
    "\n",
    "    def forward(self, x, encoder_outputs, padding_mask=None):\n",
    "        B, T_trg, C = x.shape\n",
    "        _, T_src, _ = encoder_outputs.shape\n",
    "        key = self.Wk(encoder_outputs)\n",
    "        query = self.Wq(x)\n",
    "        values = self.Wv(encoder_outputs)\n",
    "        query = query.view(B, T_trg, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        key = key.view(B, T_src, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        values = values.view(B, T_src, self.heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        attn_scores = torch.matmul(query, key.transpose(-2, -1)) * self.scale\n",
    "        attn_scores = self.add_masking(attn_scores, padding_mask)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        attn_probs_drop = self.dropout(attn_probs)\n",
    "        attn_output = torch.matmul(attn_probs_drop,values)\n",
    "        fn_attn_output = attn_output.permute(0, 2, 1, 3).reshape(B, T_trg, C)\n",
    "        return self.output(fn_attn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2d3c11c-e0eb-4294-8a28-d4142564f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm1D(nn.Module):\n",
    "  def __init__(self, dim, eps=1e-5):\n",
    "    super(LayerNorm1D, self).__init__()\n",
    "    self.gamma = nn.Parameter(torch.ones(dim))\n",
    "    self.beta = nn.Parameter(torch.zeros(dim))\n",
    "    self.eps = eps\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(-1,keepdim=True)\n",
    "    var = x.var(-1, unbiased=False, keepdim=True)\n",
    "    xhat = (x-mean)/torch.sqrt(var+self.eps)\n",
    "    return (self.gamma * xhat) +self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98007b1a-ad5f-4e48-95f9-914d43a5d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim, dropout = 0.2):\n",
    "    super().__init__()\n",
    "    self.feed_forward_layer = nn.Sequential(\n",
    "      nn.Linear(input_dim, hidden_dim),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(hidden_dim, output_dim),\n",
    "      nn.Dropout(dropout)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.feed_forward_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2262cbb3-3080-43a2-bf7f-adf398166fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self,embed_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = LayerNorm1D(embed_dim)\n",
    "        self.layer_norm2 = LayerNorm1D(embed_dim)\n",
    "        self.multi_head_attn =  MultiHeadAttention(embed_dim, heads)\n",
    "        self.feed_forward_layer = FeedForward(embed_dim, embed_dim*4, embed_dim)\n",
    "    \n",
    "    def forward(self, x, padding_mask):\n",
    "        x = x + self.multi_head_attn(self.layer_norm1(x), padding_mask)\n",
    "        x = x + self.feed_forward_layer(self.layer_norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f989fa01-bcaf-4e46-9439-706c7724a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_dim, src_vocab_size, src_max_length, heads = 4, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(src_vocab_size, embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(src_max_length, embed_dim)\n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(embed_dim,heads) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, padding_mask = None):\n",
    "        _, T = x.shape\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.positional_embedding(torch.arange(T))\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x, padding_mask = padding_mask) \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d247e06-2e0f-497b-9a90-dc5ddc5efeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self,embed_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.layer_norm1 = LayerNorm1D(embed_dim)\n",
    "        self.layer_norm2 = LayerNorm1D(embed_dim)\n",
    "        self.layer_norm3 = LayerNorm1D(embed_dim)\n",
    "        self.multi_head_attn =  MultiHeadAttention(embed_dim, heads)\n",
    "        self.cross_attn = CrossAttention(embed_dim, heads)\n",
    "        self.feed_forward_layer = FeedForward(embed_dim, embed_dim*4, embed_dim)\n",
    "    \n",
    "    def forward(self, x, encoder_outputs, src_mask, trg_mask, attn_mask = True):\n",
    "        x = x + self.multi_head_attn(self.layer_norm1(x), padding_mask = trg_mask,attn_mask = attn_mask)\n",
    "        x = x + self.cross_attn(self.layer_norm2(x), encoder_outputs, src_mask)\n",
    "        x = x + self.feed_forward_layer(self.layer_norm3(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c1b52e-7e05-42db-a395-2f6257871aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embed_dim, trg_vocab_size, trg_max_length, heads = 4, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(trg_vocab_size, embed_dim)\n",
    "        self.positional_embedding = nn.Embedding(trg_max_length, embed_dim)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(embed_dim,heads) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, encoder_outputs, src_mask = None, trg_mask = None):\n",
    "        _, T = x.shape\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.positional_embedding(torch.arange(T))\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x, encoder_outputs, src_mask, trg_mask, attn_mask = True) \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379b2f38-fa9c-4950-8d02-10fddb6863cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformers(nn.Module):\n",
    "    def __init__(self, embed_dim, src_vocab_size, src_max_length, trg_vocab_size, trg_max_length, heads = 4, encoder_layers = 4, decoder_layers = 4):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(embed_dim, src_vocab_size, src_max_length, heads = 4, num_layers = 4)\n",
    "        self.decoder = Decoder(embed_dim, trg_vocab_size, trg_max_length, heads = 4, num_layers = 4)\n",
    "        self.linear = nn.Linear(embed_dim, trg_vocab_size)\n",
    "\n",
    "    def forward(self, src, src_mask, trg, trg_mask):\n",
    "        encoder_outputs = self.encoder(src, src_mask)\n",
    "        decoder_outputs = self.decoder(trg, encoder_outputs, src_mask, trg_mask)\n",
    "        output = self.linear(decoder_outputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3c64753-92b3-473b-8065-cb1236596c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\\\Users\\\\harish-4072\\\\Downloads\\\\eng_french.csv'\n",
    "df = pd.read_csv(path, names=['English','French'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c612ce7d-4f2c-4170-a183-de4e7f7501ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()  \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  \n",
    "    tokens = text.split()  \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe6511c-b304-448a-b829-c93205ebdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = df['English'].dropna().apply(preprocess_text)\n",
    "english_vocab = Counter([token for sentence in english_sentences for token in sentence])\n",
    "\n",
    "french_sentences = df['French'].dropna().apply(preprocess_text)\n",
    "french_vocab = Counter([token for sentence in french_sentences for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6afe1286-db22-4cbf-b7fd-0ec378f8a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_token_to_id = {token: idx + 1 for idx, token in enumerate(english_vocab)}  # Start from 1 to reserve 0 for padding\n",
    "french_token_to_id = {token: idx + 3 for idx, token in enumerate(french_vocab)}\n",
    "\n",
    "english_token_to_id['<PAD>'] = 0\n",
    "\n",
    "french_token_to_id['<PAD>'] = 0\n",
    "french_token_to_id['<SOS>'] = 1\n",
    "french_token_to_id['<EOS>'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c50b87cb-fe3a-4a4a-8879-d285598ad022",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_id_to_token= {value:key for key,value in french_token_to_id.items()}\n",
    "english_id_to_token= {value:key for key,value in english_token_to_id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e84121-24b1-4188-8e4a-e30e2332289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(english_token_to_id)\n",
    "french_vocab_size = len(french_token_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92560606-fe1a-433f-9435-1168a0122ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(tokens,token_to_id):\n",
    "    return [token_to_id.get(token,0) for token in tokens]\n",
    "\n",
    "english_sequences = english_sentences.apply(lambda x: tokenize_text(x, english_token_to_id))\n",
    "french_sequences = french_sentences.apply(lambda x: tokenize_text(x, french_token_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a25fceca-d325-4120-aef5-1d8cb71db463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sos_eos(tokens):\n",
    "    return [1]+tokens+[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22074142-acf2-4d32-9281-47fa685c2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_sequences = french_sequences.apply(lambda x: add_sos_eos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91c7cb44-7b6e-4fe7-898c-ee59c61f6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(self,english_sequences,french_sequences):\n",
    "        self.english_sequences = english_sequences\n",
    "        self.french_sequences = french_sequences\n",
    "        assert len(self.english_sequences) == len(self.french_sequences)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sequences)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        X= self.english_sequences[idx]\n",
    "        y= self.french_sequences[idx]\n",
    "        return torch.tensor(X,dtype=torch.long),torch.tensor(y,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9669f7c-2bd9-430f-94c8-4a13ceb6049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    X,y = zip(*batch)\n",
    "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
    "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
    "    X_mask = (X_padded != 0) \n",
    "    y_mask = (y_padded != 0)\n",
    "    return X_padded, y_padded, X_mask, y_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24ab1db4-fe2b-4176-84e5-43f085e70a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_temp, french_temp = english_sequences[:50000].reset_index(drop=True), french_sequences[:50000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9cde863-1958-45f2-9ad9-8b406f148b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SentencesDataset(english_temp,french_temp)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,collate_fn = collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False,collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f687e0ed-ea8c-4306-b6e2-e0c56917bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 512\n",
    "HIDDEN_DIM = 128\n",
    "ENCODER_LAYERS = 4\n",
    "DECODER_LAYERS = 4\n",
    "DROPOUT = 0.5\n",
    "SRC_VOCAB_SIZE = english_vocab_size  \n",
    "PAD_IDX = 0 \n",
    "TRG_VOCAB_SIZE = french_vocab_size  \n",
    "MAX_ENGLISH_LEN = max(english_sequences.apply(len))\n",
    "MAX_FRENCH_LEN = max(french_sequences.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00c77bae-9f31-4950-9dbb-ba35c43fb332",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformers( embed_dim = EMBEDDING_DIM, src_vocab_size = SRC_VOCAB_SIZE, src_max_length = MAX_ENGLISH_LEN, trg_vocab_size = TRG_VOCAB_SIZE, trg_max_length = MAX_FRENCH_LEN, heads = 4, encoder_layers = ENCODER_LAYERS, decoder_layers = DECODER_LAYERS)\n",
    "if os.path.exists(\"transformers_model.pth\"):\n",
    "    model.load_state_dict(torch.load(\"transformers_model.pth\")) \n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c93d8c1-696d-4d3e-9419-af33d5b65589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model :nn.Module, criterion: nn.Module, optimizer: torch.optim, train_data: DataLoader, epochs: int = 4):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X,y, X_mask, y_mask in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X, X_mask, y, y_mask)\n",
    "            outputs = outputs[:,:-1,:]\n",
    "            y = y[:,1:]\n",
    "            loss = criterion(outputs.reshape(-1,TRG_VOCAB_SIZE), y.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "            torch.save(model.state_dict(), \"transformers_model.pth\")\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6645564f-cbd4-47bb-8b86-a399051743f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: 4.1294\n",
      "Epoch: 2/10, Loss: 1.7837\n",
      "Epoch: 3/10, Loss: 1.2125\n",
      "Epoch: 4/10, Loss: 0.9845\n",
      "Epoch: 5/10, Loss: 0.8690\n",
      "Epoch: 6/10, Loss: 0.8051\n",
      "Epoch: 7/10, Loss: 0.7723\n",
      "Epoch: 8/10, Loss: 0.7485\n",
      "Epoch: 9/10, Loss: 0.7236\n",
      "Epoch: 10/10, Loss: 0.7249\n"
     ]
    }
   ],
   "source": [
    "train(model, criterion, optimizer, train_loader, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "affadaf3-73a0-4158-b914-8e6e6143f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model :nn.Module, criterion: nn.Module, optimizer: torch.optim, val_data: DataLoader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X,y, X_mask, y_mask in val_data:\n",
    "            outputs = model(X, X_mask, y, y_mask)\n",
    "            outputs = outputs[:,1:,:]\n",
    "            y = y[:,1:]\n",
    "            loss = criterion(outputs.reshape(-1,TRG_VOCAB_SIZE), y.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "        print(f\"Loss: {val_loss / len(val_data):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8b9c261-b8d7-4c65-9a64-f3fdd1d4d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.7992\n"
     ]
    }
   ],
   "source": [
    "val(model, criterion, optimizer, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50315497-ccc8-4e39-bf40-ab9eaedad225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model :nn.Module, criterion: nn.Module, optimizer: torch.optim, input: torch.tensor):\n",
    "    output_tokens = []\n",
    "    encoder_outputs = model.encoder(input,None)\n",
    "    current_token = torch.tensor([[0]]) #SOS token\n",
    "    i = 0\n",
    "    while True:\n",
    "        prediction = model.decoder(current_token, encoder_outputs, None, None)\n",
    "        pred_probs = model.linear(prediction)\n",
    "        logits = pred_probs[:, -1, :]\n",
    "        next_token = logits.argmax(-1)\n",
    "        if next_token.item() == 2: #EOS token\n",
    "                break\n",
    "        output_tokens.append(next_token.item())\n",
    "        current_token = torch.cat([current_token, torch.tensor([[next_token]])], dim=1)\n",
    "        \n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ddcbef7-dd35-486f-8ed1-5c84a8777533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def generate_topk(model :nn.Module, criterion: nn.Module, optimizer: torch.optim, input: torch.tensor, k: int =5):\n",
    "    output_tokens = []\n",
    "    encoder_outputs = model.encoder(input,None)\n",
    "    current_token = torch.tensor([[0]]) #SOS token\n",
    "    i = 0\n",
    "    while True:\n",
    "        prediction = model.decoder(current_token, encoder_outputs, None, None)\n",
    "        pred_probs = model.linear(prediction)\n",
    "        logits = pred_probs[:, -1, :].squeeze(0)\n",
    "        top_k_logits, top_k_indices = torch.topk(logits, k)\n",
    "        top_k_probs = F.softmax(top_k_logits, dim=-1)\n",
    "        next_token = top_k_indices[torch.multinomial(top_k_probs, 1).item()]\n",
    "        if next_token.item() == 2: #EOS token\n",
    "                break\n",
    "        output_tokens.append(next_token.item())\n",
    "        current_token = torch.cat([current_token, torch.tensor([[next_token]])], dim=1)\n",
    "        \n",
    "    return output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28229054-94d1-4f42-8a53-2a3424b10926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "098ce961-f6a9-4b4a-9610-9583af8a917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"are you stupid?\"\n",
    "text = preprocess_text(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58408f72-7a15-4eb8-a697-affff988f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(tokenize_text(text, english_token_to_id)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "eca0bcbc-5d11-4563-a122-1c60e14532bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = torch.tensor(english_sequences[1000]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "01248c67-3c34-409e-b785-62b6b510ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = generate(model, criterion, optimizer, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d44fd0ae-486d-4584-8ba4-5a01e8d832c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tesvous', 'aussi', 'btes']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[french_id_to_token[idx] for idx in translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ba449e7e-eacd-4934-866a-58c5e2daade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = generate_topk(model, criterion, optimizer, input, k =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e05ac8f3-635b-4ea8-9e6a-5ba6e4422d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stupide']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[french_id_to_token[idx] for idx in translation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "26763276-96df-456f-b15e-dd910cc6f9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['were', 'shy']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[english_id_to_token[idx] for idx in english_sequences[1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89155bad-5f4b-453c-b6ea-d884dd2e6ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
